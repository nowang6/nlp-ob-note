  

# 第三题
Q3: Largest Sum Subarray:“Given an array, find the contiguous subarray with the largest sum.”

Hints:

- Your program only needs to return the sum of the values, not the indexes of the subarray.

- using python or any language you prefer
``` python
Array1 = [-4, 2, -5, 1, 2, 3, 6, -5, 1, 5, 7, -3, 6 ]
```

# 第四题
Q4: Implement a basic Reinforcement Learning algorithm which is called the Q-Learning technique: “Teach a bot to reach its destination using the Q-Learning”

Hints:

- using python or any language you prefer

- goal: destination node index

```python
#----------------------------------------------------------------------------------------------

# 1). Importing the libs

import numpy as np

import pylab as pl

import networkx as nx

#----------------------------------------------------------------------------------------------

# 2). The graph

edges = [(0, 1), (1, 5), (5, 6), (5, 4), (1, 2),

(1, 3), (9, 10), (2, 4), (0, 6), (6, 7),

(8, 9), (7, 8), (1, 7), (3, 9)]

goal = 10

G = nx.Graph()

G.add_edges_from(edges)

pos = nx.spring_layout(G)

nx.draw_networkx_nodes(G, pos)

nx.draw_networkx_edges(G, pos)

nx.draw_networkx_labels(G, pos)

pl.show()

#----------------------------------------------------------------------------------------------

# 3). Rewarding system

MATRIX_SIZE = 11

M = np.matrix(np.ones(shape =(MATRIX_SIZE, MATRIX_SIZE)))

M *= -1

for point in edges:

print(point)

if point[1] == goal:

M[point] = 100

else:

M[point] = 0

if point[0] == goal:

M[point[::-1]] = 100

else:

# reverse of point

M[point[::-1]]= 0

# add goal point round trip

M[goal, goal]= 100

print(M)

#----------------------------------------------------------------------------------------------

# 4). Utility functions

Q = np.matrix(np.zeros([MATRIX_SIZE, MATRIX_SIZE]))

# learning parameter

gamma = 0.75

initial_state = 1

def available_actions(state):

    #return available_action_list

    # Your codes here 1: 

    pass

available_action = available_actions(initial_state)

def sample_next_action(available_actions_range):

next_action = int(np.random.choice(available_actions_range, 1))

return next_action

action = sample_next_action(available_action)

def update(current_state, action, gamma):

    # Your codes here 2:

    # Return score:

    pass

# Updating the Q-Matrix according to the path chosen

update(initial_state, action, gamma)

#----------------------------------------------------------------------------------------------

# 5). Training

scores = []

for i in range(1000):

# steps for the current state: 

    current_state = np.random.randint(0, int(Q.shape[0]))

    # Your codes here 3:    

    pass

print("Trained Q matrix:")

print(Q / np.max(Q)*100)

#----------------------------------------------------------------------------------------------

# 6). Testing

current_state = 0

steps = [current_state]

while current_state != 10:

next_step_index = np.where(Q[current_state, ] == np.max(Q[current_state, ]))[1]

if next_step_index.shape[0] > 1:

next_step_index = int(np.random.choice(next_step_index, size = 1))

else:

next_step_index = int(next_step_index)

steps.append(next_step_index)

current_state = next_step_index

print("Most efficient path:")

print(steps)

pl.plot(scores)

pl.xlabel('No of iterations')

pl.ylabel('Reward gained')

pl.show()
```

#  第五题
#### Q5: How would you build a data pipeline?

Hints:

- Explain the steps required in a functioning data pipeline and talk through your actual experience building and scaling them in production.